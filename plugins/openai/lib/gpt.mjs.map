{"version":3,"sources":["../src/gpt.ts"],"sourcesContent":["/**\n * Copyright 2024 The Fire Company\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Message } from '@genkit-ai/ai';\nimport {\n  GenerateResponseChunkData,\n  GenerateResponseData,\n  GenerationCommonConfigSchema,\n  ModelAction,\n  defineModel,\n  modelRef,\n  type CandidateData,\n  type GenerateRequest,\n  type MessageData,\n  type Part,\n  type Role,\n  type ToolDefinition,\n  type ToolRequestPart,\n} from '@genkit-ai/ai/model';\nimport { StreamingCallback } from '@genkit-ai/core';\nimport OpenAI from 'openai';\nimport {\n  type ChatCompletion,\n  type ChatCompletionChunk,\n  type ChatCompletionContentPart,\n  type ChatCompletionCreateParamsNonStreaming,\n  type ChatCompletionMessageParam,\n  type ChatCompletionMessageToolCall,\n  type ChatCompletionRole,\n  type ChatCompletionTool,\n  type CompletionChoice,\n} from 'openai/resources/index.mjs';\nimport z from 'zod';\n\nconst MODELS_SUPPORTING_OPENAI_RESPONSE_FORMAT = [\n  'gpt-4o',\n  'gpt-4o-2024-05-13',\n  'gpt-4o-mini',\n  'gpt-4o-mini-2024-07-18',\n  'gpt-4-turbo',\n  'gpt-4-turbo-2024-04-09',\n  'gpt-4-turbo-preview',\n  'gpt-4-0125-preview',\n  'gpt-4-1106-preview',\n  'gpt-3.5-turbo-0125',\n  'gpt-3.5-turbo',\n  'gpt-3.5-turbo-1106',\n];\n\nexport const OpenAiConfigSchema = GenerationCommonConfigSchema.extend({\n  frequencyPenalty: z.number().min(-2).max(2).optional(),\n  logitBias: z.record(z.string(), z.number().min(-100).max(100)).optional(),\n  logProbs: z.boolean().optional(),\n  presencePenalty: z.number().min(-2).max(2).optional(),\n  seed: z.number().int().optional(),\n  topLogProbs: z.number().int().min(0).max(20).optional(),\n  user: z.string().optional(),\n  visualDetailLevel: z.enum(['auto', 'low', 'high']).optional(),\n});\n\ntype VisualDetailLevel = z.infer<\n  typeof OpenAiConfigSchema\n>['visualDetailLevel'];\n\nexport const gpt4o = modelRef({\n  name: 'openai/gpt-4o',\n  info: {\n    versions: ['gpt-4o', 'gpt-4o-2024-05-13'],\n    label: 'OpenAI - GPT-4o',\n    supports: {\n      multiturn: true,\n      tools: true,\n      media: true,\n      systemRole: true,\n      output: ['text', 'json'],\n    },\n  },\n  configSchema: OpenAiConfigSchema,\n});\n\nexport const gpt4oMini = modelRef({\n  name: 'openai/gpt-4o-mini',\n  info: {\n    versions: ['gpt-4o-mini', 'gpt-4o-mini-2024-07-18'],\n    label: 'OpenAI - GPT-4o mini',\n    supports: {\n      multiturn: true,\n      tools: true,\n      media: true,\n      systemRole: true,\n      output: ['text', 'json'],\n    },\n  },\n  configSchema: OpenAiConfigSchema,\n});\n\nexport const gpt4Turbo = modelRef({\n  name: 'openai/gpt-4-turbo',\n  info: {\n    versions: [\n      'gpt-4-turbo',\n      'gpt-4-turbo-2024-04-09',\n      'gpt-4-turbo-preview',\n      'gpt-4-0125-preview',\n      'gpt-4-1106-preview',\n    ],\n    label: 'OpenAI - GPT-4 Turbo',\n    supports: {\n      multiturn: true,\n      tools: true,\n      media: true,\n      systemRole: true,\n      output: ['text', 'json'],\n    },\n  },\n  configSchema: OpenAiConfigSchema,\n});\n\nexport const gpt4Vision = modelRef({\n  name: 'openai/gpt-4-vision',\n  info: {\n    versions: ['gpt-4-vision-preview', 'gpt-4-1106-vision-preview'],\n    label: 'OpenAI - GPT-4 Vision',\n    supports: {\n      multiturn: true,\n      tools: false,\n      media: true,\n      systemRole: true,\n      output: ['text'],\n    },\n  },\n  configSchema: OpenAiConfigSchema,\n});\n\nexport const gpt4 = modelRef({\n  name: 'openai/gpt-4',\n  info: {\n    versions: ['gpt-4', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0613'],\n    label: 'OpenAI - GPT-4',\n    supports: {\n      multiturn: true,\n      tools: true,\n      media: false,\n      systemRole: true,\n      output: ['text'],\n    },\n  },\n  configSchema: OpenAiConfigSchema,\n});\n\nexport const gpt35Turbo = modelRef({\n  name: 'openai/gpt-3.5-turbo',\n  info: {\n    versions: ['gpt-3.5-turbo-0125', 'gpt-3.5-turbo', 'gpt-3.5-turbo-1106'],\n    label: 'OpenAI - GPT-3.5 Turbo',\n    supports: {\n      multiturn: true,\n      tools: true,\n      media: false,\n      systemRole: true,\n      output: ['json', 'text'],\n    },\n  },\n  configSchema: OpenAiConfigSchema,\n});\n\nexport const SUPPORTED_GPT_MODELS = {\n  'gpt-4o': gpt4o,\n  'gpt-4o-mini': gpt4oMini,\n  'gpt-4-turbo': gpt4Turbo,\n  'gpt-4-vision': gpt4Vision,\n  'gpt-4': gpt4,\n  'gpt-3.5-turbo': gpt35Turbo,\n};\n\nexport function toOpenAIRole(role: Role): ChatCompletionRole {\n  switch (role) {\n    case 'user':\n      return 'user';\n    case 'model':\n      return 'assistant';\n    case 'system':\n      return 'system';\n    case 'tool':\n      return 'tool';\n    default:\n      throw new Error(`role ${role} doesn't map to an OpenAI role.`);\n  }\n}\n\n/**\n * Converts a Genkit ToolDefinition to an OpenAI ChatCompletionTool object.\n * @param tool The Genkit ToolDefinition to convert.\n * @returns The converted OpenAI ChatCompletionTool object.\n */\nfunction toOpenAiTool(tool: ToolDefinition): ChatCompletionTool {\n  return {\n    type: 'function',\n    function: {\n      name: tool.name,\n      parameters: tool.inputSchema,\n    },\n  };\n}\n\n/**\n * Converts a Genkit Part to the corresponding OpenAI ChatCompletionContentPart.\n * @param part The Genkit Part to convert.\n * @param visualDetailLevel The visual detail level to use for media parts.\n * @returns The corresponding OpenAI ChatCompletionContentPart.\n * @throws Error if the part contains unsupported fields for the current message role.\n */\nexport function toOpenAiTextAndMedia(\n  part: Part,\n  visualDetailLevel: VisualDetailLevel\n): ChatCompletionContentPart {\n  if (part.text) {\n    return {\n      type: 'text',\n      text: part.text,\n    };\n  } else if (part.media) {\n    return {\n      type: 'image_url',\n      image_url: {\n        url: part.media.url,\n        detail: visualDetailLevel,\n      },\n    };\n  }\n  throw Error(\n    `Unsupported genkit part fields encountered for current message role: ${JSON.stringify(part)}.`\n  );\n}\n\n/**\n * Converts a Genkit MessageData array to an OpenAI ChatCompletionMessageParam array.\n * @param messages The Genkit MessageData array to convert.\n * @param visualDetailLevel The visual detail level to use for media parts.\n * @returns The converted OpenAI ChatCompletionMessageParam array.\n */\nexport function toOpenAiMessages(\n  messages: MessageData[],\n  visualDetailLevel: VisualDetailLevel = 'auto'\n): ChatCompletionMessageParam[] {\n  const openAiMsgs: ChatCompletionMessageParam[] = [];\n  for (const message of messages) {\n    const msg = new Message(message);\n    const role = toOpenAIRole(message.role);\n    switch (role) {\n      case 'user':\n        openAiMsgs.push({\n          role: role,\n          content: msg.content.map((part) =>\n            toOpenAiTextAndMedia(part, visualDetailLevel)\n          ),\n        });\n        break;\n      case 'system':\n        openAiMsgs.push({\n          role: role,\n          content: msg.text(),\n        });\n        break;\n      case 'assistant': {\n        const toolCalls: ChatCompletionMessageToolCall[] = msg.content\n          .filter(\n            (\n              part\n            ): part is Part & {\n              toolRequest: NonNullable<Part['toolRequest']>;\n            } => Boolean(part.toolRequest)\n          )\n          .map((part) => ({\n            id: part.toolRequest.ref ?? '',\n            type: 'function',\n            function: {\n              name: part.toolRequest.name,\n              arguments: JSON.stringify(part.toolRequest.input),\n            },\n          }));\n        if (toolCalls.length > 0) {\n          openAiMsgs.push({\n            role: role,\n            tool_calls: toolCalls,\n          });\n        } else {\n          openAiMsgs.push({\n            role: role,\n            content: msg.text(),\n          });\n        }\n        break;\n      }\n      case 'tool': {\n        const toolResponseParts = msg.toolResponseParts();\n        toolResponseParts.map((part) => {\n          openAiMsgs.push({\n            role: role,\n            tool_call_id: part.toolResponse.ref ?? '',\n            content:\n              typeof part.toolResponse.output === 'string'\n                ? part.toolResponse.output\n                : JSON.stringify(part.toolResponse.output),\n          });\n        });\n        break;\n      }\n    }\n  }\n  return openAiMsgs;\n}\n\nconst finishReasonMap: Record<\n  // OpenAI Node SDK doesn't support tool_call in the enum, but it is returned from the API\n  CompletionChoice['finish_reason'] | 'tool_calls',\n  CandidateData['finishReason']\n> = {\n  length: 'length',\n  stop: 'stop',\n  tool_calls: 'stop',\n  content_filter: 'blocked',\n};\n\n/**\n * Converts an OpenAI tool call to a Genkit ToolRequestPart.\n * @param toolCall The OpenAI tool call to convert.\n * @returns The converted Genkit ToolRequestPart.\n */\nexport function fromOpenAiToolCall(\n  toolCall:\n    | ChatCompletionMessageToolCall\n    | ChatCompletionChunk.Choice.Delta.ToolCall\n): ToolRequestPart {\n  if (!toolCall.function) {\n    throw Error(\n      `Unexpected openAI chunk choice. tool_calls was provided but one or more tool_calls is missing.`\n    );\n  }\n  const f = toolCall.function;\n  return {\n    toolRequest: {\n      name: f.name!,\n      ref: toolCall.id,\n      input: f.arguments ? JSON.parse(f.arguments) : f.arguments,\n    },\n  };\n}\n\n/**\n * Converts an OpenAI message event to a Genkit CandidateData object.\n * @param choice The OpenAI message event to convert.\n * @param jsonMode Whether the event is a JSON response.\n * @returns The converted Genkit CandidateData object.\n */\nexport function fromOpenAiChoice(\n  choice: ChatCompletion.Choice,\n  jsonMode = false\n): CandidateData {\n  const toolRequestParts = choice.message.tool_calls?.map(fromOpenAiToolCall);\n  return {\n    index: choice.index,\n    finishReason: finishReasonMap[choice.finish_reason] || 'other',\n    message: {\n      role: 'model',\n      content: toolRequestParts && toolRequestParts.length > 0\n        ? // Note: Not sure why I have to cast here exactly.\n          // Otherwise it thinks toolRequest must be 'undefined' if provided\n          (toolRequestParts as ToolRequestPart[])\n        : [\n            jsonMode\n              ? { data: JSON.parse(choice.message.content!) }\n              : { text: choice.message.content! },\n          ],\n    },\n    custom: {},\n  };\n}\n\n/**\n * Converts an OpenAI message stream event to a Genkit CandidateData object.\n * @param choice The OpenAI message stream event to convert.\n * @param jsonMode Whether the event is a JSON response.\n * @returns The converted Genkit CandidateData object.\n */\nexport function fromOpenAiChunkChoice(\n  choice: ChatCompletionChunk.Choice,\n  jsonMode = false\n): CandidateData {\n  const toolRequestParts = choice.delta.tool_calls?.map(fromOpenAiToolCall);\n  return {\n    index: choice.index,\n    finishReason: choice.finish_reason\n      ? finishReasonMap[choice.finish_reason] || 'other'\n      : 'unknown',\n    message: {\n      role: 'model',\n      content: toolRequestParts\n        ? // Note: Not sure why I have to cast here exactly.\n          // Otherwise it thinks toolRequest must be 'undefined' if provided\n          (toolRequestParts as ToolRequestPart[])\n        : [\n            jsonMode\n              ? { data: JSON.parse(choice.delta.content!) }\n              : { text: choice.delta.content! },\n          ],\n    },\n    custom: {},\n  };\n}\n\n/**\n * Converts an OpenAI request to an OpenAI API request body.\n * @param modelName The name of the OpenAI model to use.\n * @param request The Genkit GenerateRequest to convert.\n * @returns The converted OpenAI API request body.\n * @throws An error if the specified model is not supported or if an unsupported output format is requested.\n */\nexport function toOpenAiRequestBody(\n  modelName: string,\n  request: GenerateRequest<typeof OpenAiConfigSchema>\n) {\n  const model = SUPPORTED_GPT_MODELS[modelName];\n  if (!model) throw new Error(`Unsupported model: ${modelName}`);\n  const openAiMessages = toOpenAiMessages(\n    request.messages,\n    request.config?.visualDetailLevel\n  );\n  const mappedModelName = request.config?.version || model.version || modelName;\n  const body = {\n    model: mappedModelName,\n    messages: openAiMessages,\n    temperature: request.config?.temperature,\n    max_tokens: request.config?.maxOutputTokens,\n    top_p: request.config?.topP,\n    stop: request.config?.stopSequences,\n    frequency_penalty: request.config?.frequencyPenalty,\n    logit_bias: request.config?.logitBias,\n    logprobs: request.config?.logProbs, // logprobs not snake case!\n    presence_penalty: request.config?.presencePenalty,\n    seed: request.config?.seed,\n    top_logprobs: request.config?.topLogProbs, // logprobs not snake case!\n    user: request.config?.user,\n    tools: request.tools?.map(toOpenAiTool),\n    n: request.candidates,\n  } as ChatCompletionCreateParamsNonStreaming;\n\n  const response_format = request.output?.format;\n  if (\n    response_format &&\n    MODELS_SUPPORTING_OPENAI_RESPONSE_FORMAT.includes(mappedModelName)\n  ) {\n    if (\n      response_format === 'json' &&\n      model.info.supports?.output?.includes('json')\n    ) {\n      body.response_format = {\n        type: 'json_object',\n      };\n    } else if (\n      response_format === 'text' &&\n      model.info.supports?.output?.includes('text')\n    ) {\n      body.response_format = {\n        type: 'text',\n      };\n    } else {\n      throw new Error(\n        `${response_format} format is not supported for GPT models currently`\n      );\n    }\n  }\n  for (const key in body) {\n    if (!body[key] || (Array.isArray(body[key]) && !body[key].length))\n      delete body[key];\n  }\n  return body;\n}\n\n/**\n * Creates the runner used by Genkit to interact with the GPT model.\n * @param name The name of the GPT model.\n * @param client The OpenAI client instance.\n * @returns The runner that Genkit will call when the model is invoked.\n */\nexport function gptRunner(name: string, client: OpenAI) {\n  return async (\n    request: GenerateRequest<typeof OpenAiConfigSchema>,\n    streamingCallback?: StreamingCallback<GenerateResponseChunkData>\n  ): Promise<GenerateResponseData> => {\n    let response: ChatCompletion;\n    const body = toOpenAiRequestBody(name, request);\n    if (streamingCallback) {\n      const stream = client.beta.chat.completions.stream({\n        ...body,\n        stream: true,\n      });\n      for await (const chunk of stream) {\n        chunk.choices?.forEach((chunk) => {\n          const c = fromOpenAiChunkChoice(chunk);\n          streamingCallback({\n            index: c.index,\n            content: c.message.content,\n          });\n        });\n      }\n      response = await stream.finalChatCompletion();\n    } else {\n      response = await client.chat.completions.create(body);\n    }\n    return {\n      candidates: response.choices.map((c) =>\n        fromOpenAiChoice(c, request.output?.format === 'json')\n      ),\n      usage: {\n        inputTokens: response.usage?.prompt_tokens,\n        outputTokens: response.usage?.completion_tokens,\n        totalTokens: response.usage?.total_tokens,\n      },\n      custom: response,\n    };\n  };\n}\n\n/**\n * Defines a GPT model with the given name and OpenAI client.\n * @param name The name of the GPT model.\n * @param client The OpenAI client instance.\n * @returns The defined GPT model.\n * @throws An error if the specified model is not supported.\n */\nexport function gptModel(\n  name: string,\n  client: OpenAI\n): ModelAction<typeof OpenAiConfigSchema> {\n  const modelId = `openai/${name}`;\n  const model = SUPPORTED_GPT_MODELS[name];\n  if (!model) throw new Error(`Unsupported model: ${name}`);\n\n  return defineModel(\n    {\n      name: modelId,\n      ...model.info,\n      configSchema: model.configSchema,\n    },\n    gptRunner(name, client)\n  );\n}\n"],"mappings":";;;;;;AAgBA,SAAS,eAAe;AACxB;AAAA,EAGE;AAAA,EAEA;AAAA,EACA;AAAA,OAQK;AAcP,OAAO,OAAO;AAEd,MAAM,2CAA2C;AAAA,EAC/C;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAEO,MAAM,qBAAqB,6BAA6B,OAAO;AAAA,EACpE,kBAAkB,EAAE,OAAO,EAAE,IAAI,EAAE,EAAE,IAAI,CAAC,EAAE,SAAS;AAAA,EACrD,WAAW,EAAE,OAAO,EAAE,OAAO,GAAG,EAAE,OAAO,EAAE,IAAI,IAAI,EAAE,IAAI,GAAG,CAAC,EAAE,SAAS;AAAA,EACxE,UAAU,EAAE,QAAQ,EAAE,SAAS;AAAA,EAC/B,iBAAiB,EAAE,OAAO,EAAE,IAAI,EAAE,EAAE,IAAI,CAAC,EAAE,SAAS;AAAA,EACpD,MAAM,EAAE,OAAO,EAAE,IAAI,EAAE,SAAS;AAAA,EAChC,aAAa,EAAE,OAAO,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,IAAI,EAAE,EAAE,SAAS;AAAA,EACtD,MAAM,EAAE,OAAO,EAAE,SAAS;AAAA,EAC1B,mBAAmB,EAAE,KAAK,CAAC,QAAQ,OAAO,MAAM,CAAC,EAAE,SAAS;AAC9D,CAAC;AAMM,MAAM,QAAQ,SAAS;AAAA,EAC5B,MAAM;AAAA,EACN,MAAM;AAAA,IACJ,UAAU,CAAC,UAAU,mBAAmB;AAAA,IACxC,OAAO;AAAA,IACP,UAAU;AAAA,MACR,WAAW;AAAA,MACX,OAAO;AAAA,MACP,OAAO;AAAA,MACP,YAAY;AAAA,MACZ,QAAQ,CAAC,QAAQ,MAAM;AAAA,IACzB;AAAA,EACF;AAAA,EACA,cAAc;AAChB,CAAC;AAEM,MAAM,YAAY,SAAS;AAAA,EAChC,MAAM;AAAA,EACN,MAAM;AAAA,IACJ,UAAU,CAAC,eAAe,wBAAwB;AAAA,IAClD,OAAO;AAAA,IACP,UAAU;AAAA,MACR,WAAW;AAAA,MACX,OAAO;AAAA,MACP,OAAO;AAAA,MACP,YAAY;AAAA,MACZ,QAAQ,CAAC,QAAQ,MAAM;AAAA,IACzB;AAAA,EACF;AAAA,EACA,cAAc;AAChB,CAAC;AAEM,MAAM,YAAY,SAAS;AAAA,EAChC,MAAM;AAAA,EACN,MAAM;AAAA,IACJ,UAAU;AAAA,MACR;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAAA,IACA,OAAO;AAAA,IACP,UAAU;AAAA,MACR,WAAW;AAAA,MACX,OAAO;AAAA,MACP,OAAO;AAAA,MACP,YAAY;AAAA,MACZ,QAAQ,CAAC,QAAQ,MAAM;AAAA,IACzB;AAAA,EACF;AAAA,EACA,cAAc;AAChB,CAAC;AAEM,MAAM,aAAa,SAAS;AAAA,EACjC,MAAM;AAAA,EACN,MAAM;AAAA,IACJ,UAAU,CAAC,wBAAwB,2BAA2B;AAAA,IAC9D,OAAO;AAAA,IACP,UAAU;AAAA,MACR,WAAW;AAAA,MACX,OAAO;AAAA,MACP,OAAO;AAAA,MACP,YAAY;AAAA,MACZ,QAAQ,CAAC,MAAM;AAAA,IACjB;AAAA,EACF;AAAA,EACA,cAAc;AAChB,CAAC;AAEM,MAAM,OAAO,SAAS;AAAA,EAC3B,MAAM;AAAA,EACN,MAAM;AAAA,IACJ,UAAU,CAAC,SAAS,cAAc,aAAa,gBAAgB;AAAA,IAC/D,OAAO;AAAA,IACP,UAAU;AAAA,MACR,WAAW;AAAA,MACX,OAAO;AAAA,MACP,OAAO;AAAA,MACP,YAAY;AAAA,MACZ,QAAQ,CAAC,MAAM;AAAA,IACjB;AAAA,EACF;AAAA,EACA,cAAc;AAChB,CAAC;AAEM,MAAM,aAAa,SAAS;AAAA,EACjC,MAAM;AAAA,EACN,MAAM;AAAA,IACJ,UAAU,CAAC,sBAAsB,iBAAiB,oBAAoB;AAAA,IACtE,OAAO;AAAA,IACP,UAAU;AAAA,MACR,WAAW;AAAA,MACX,OAAO;AAAA,MACP,OAAO;AAAA,MACP,YAAY;AAAA,MACZ,QAAQ,CAAC,QAAQ,MAAM;AAAA,IACzB;AAAA,EACF;AAAA,EACA,cAAc;AAChB,CAAC;AAEM,MAAM,uBAAuB;AAAA,EAClC,UAAU;AAAA,EACV,eAAe;AAAA,EACf,eAAe;AAAA,EACf,gBAAgB;AAAA,EAChB,SAAS;AAAA,EACT,iBAAiB;AACnB;AAEO,SAAS,aAAa,MAAgC;AAC3D,UAAQ,MAAM;AAAA,IACZ,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,IACT;AACE,YAAM,IAAI,MAAM,QAAQ,IAAI,iCAAiC;AAAA,EACjE;AACF;AAOA,SAAS,aAAa,MAA0C;AAC9D,SAAO;AAAA,IACL,MAAM;AAAA,IACN,UAAU;AAAA,MACR,MAAM,KAAK;AAAA,MACX,YAAY,KAAK;AAAA,IACnB;AAAA,EACF;AACF;AASO,SAAS,qBACd,MACA,mBAC2B;AAC3B,MAAI,KAAK,MAAM;AACb,WAAO;AAAA,MACL,MAAM;AAAA,MACN,MAAM,KAAK;AAAA,IACb;AAAA,EACF,WAAW,KAAK,OAAO;AACrB,WAAO;AAAA,MACL,MAAM;AAAA,MACN,WAAW;AAAA,QACT,KAAK,KAAK,MAAM;AAAA,QAChB,QAAQ;AAAA,MACV;AAAA,IACF;AAAA,EACF;AACA,QAAM;AAAA,IACJ,wEAAwE,KAAK,UAAU,IAAI,CAAC;AAAA,EAC9F;AACF;AAQO,SAAS,iBACd,UACA,oBAAuC,QACT;AAC9B,QAAM,aAA2C,CAAC;AAClD,aAAW,WAAW,UAAU;AAC9B,UAAM,MAAM,IAAI,QAAQ,OAAO;AAC/B,UAAM,OAAO,aAAa,QAAQ,IAAI;AACtC,YAAQ,MAAM;AAAA,MACZ,KAAK;AACH,mBAAW,KAAK;AAAA,UACd;AAAA,UACA,SAAS,IAAI,QAAQ;AAAA,YAAI,CAAC,SACxB,qBAAqB,MAAM,iBAAiB;AAAA,UAC9C;AAAA,QACF,CAAC;AACD;AAAA,MACF,KAAK;AACH,mBAAW,KAAK;AAAA,UACd;AAAA,UACA,SAAS,IAAI,KAAK;AAAA,QACpB,CAAC;AACD;AAAA,MACF,KAAK,aAAa;AAChB,cAAM,YAA6C,IAAI,QACpD;AAAA,UACC,CACE,SAGG,QAAQ,KAAK,WAAW;AAAA,QAC/B,EACC,IAAI,CAAC,SAAM;AA9RtB;AA8R0B;AAAA,YACd,KAAI,UAAK,YAAY,QAAjB,YAAwB;AAAA,YAC5B,MAAM;AAAA,YACN,UAAU;AAAA,cACR,MAAM,KAAK,YAAY;AAAA,cACvB,WAAW,KAAK,UAAU,KAAK,YAAY,KAAK;AAAA,YAClD;AAAA,UACF;AAAA,SAAE;AACJ,YAAI,UAAU,SAAS,GAAG;AACxB,qBAAW,KAAK;AAAA,YACd;AAAA,YACA,YAAY;AAAA,UACd,CAAC;AAAA,QACH,OAAO;AACL,qBAAW,KAAK;AAAA,YACd;AAAA,YACA,SAAS,IAAI,KAAK;AAAA,UACpB,CAAC;AAAA,QACH;AACA;AAAA,MACF;AAAA,MACA,KAAK,QAAQ;AACX,cAAM,oBAAoB,IAAI,kBAAkB;AAChD,0BAAkB,IAAI,CAAC,SAAS;AArTxC;AAsTU,qBAAW,KAAK;AAAA,YACd;AAAA,YACA,eAAc,UAAK,aAAa,QAAlB,YAAyB;AAAA,YACvC,SACE,OAAO,KAAK,aAAa,WAAW,WAChC,KAAK,aAAa,SAClB,KAAK,UAAU,KAAK,aAAa,MAAM;AAAA,UAC/C,CAAC;AAAA,QACH,CAAC;AACD;AAAA,MACF;AAAA,IACF;AAAA,EACF;AACA,SAAO;AACT;AAEA,MAAM,kBAIF;AAAA,EACF,QAAQ;AAAA,EACR,MAAM;AAAA,EACN,YAAY;AAAA,EACZ,gBAAgB;AAClB;AAOO,SAAS,mBACd,UAGiB;AACjB,MAAI,CAAC,SAAS,UAAU;AACtB,UAAM;AAAA,MACJ;AAAA,IACF;AAAA,EACF;AACA,QAAM,IAAI,SAAS;AACnB,SAAO;AAAA,IACL,aAAa;AAAA,MACX,MAAM,EAAE;AAAA,MACR,KAAK,SAAS;AAAA,MACd,OAAO,EAAE,YAAY,KAAK,MAAM,EAAE,SAAS,IAAI,EAAE;AAAA,IACnD;AAAA,EACF;AACF;AAQO,SAAS,iBACd,QACA,WAAW,OACI;AAnXjB;AAoXE,QAAM,oBAAmB,YAAO,QAAQ,eAAf,mBAA2B,IAAI;AACxD,SAAO;AAAA,IACL,OAAO,OAAO;AAAA,IACd,cAAc,gBAAgB,OAAO,aAAa,KAAK;AAAA,IACvD,SAAS;AAAA,MACP,MAAM;AAAA,MACN,SAAS,oBAAoB,iBAAiB,SAAS;AAAA;AAAA;AAAA,QAGlD;AAAA,UACD;AAAA,QACE,WACI,EAAE,MAAM,KAAK,MAAM,OAAO,QAAQ,OAAQ,EAAE,IAC5C,EAAE,MAAM,OAAO,QAAQ,QAAS;AAAA,MACtC;AAAA,IACN;AAAA,IACA,QAAQ,CAAC;AAAA,EACX;AACF;AAQO,SAAS,sBACd,QACA,WAAW,OACI;AAjZjB;AAkZE,QAAM,oBAAmB,YAAO,MAAM,eAAb,mBAAyB,IAAI;AACtD,SAAO;AAAA,IACL,OAAO,OAAO;AAAA,IACd,cAAc,OAAO,gBACjB,gBAAgB,OAAO,aAAa,KAAK,UACzC;AAAA,IACJ,SAAS;AAAA,MACP,MAAM;AAAA,MACN,SAAS;AAAA;AAAA;AAAA,QAGJ;AAAA,UACD;AAAA,QACE,WACI,EAAE,MAAM,KAAK,MAAM,OAAO,MAAM,OAAQ,EAAE,IAC1C,EAAE,MAAM,OAAO,MAAM,QAAS;AAAA,MACpC;AAAA,IACN;AAAA,IACA,QAAQ,CAAC;AAAA,EACX;AACF;AASO,SAAS,oBACd,WACA,SACA;AAlbF;AAmbE,QAAM,QAAQ,qBAAqB,SAAS;AAC5C,MAAI,CAAC;AAAO,UAAM,IAAI,MAAM,sBAAsB,SAAS,EAAE;AAC7D,QAAM,iBAAiB;AAAA,IACrB,QAAQ;AAAA,KACR,aAAQ,WAAR,mBAAgB;AAAA,EAClB;AACA,QAAM,oBAAkB,aAAQ,WAAR,mBAAgB,YAAW,MAAM,WAAW;AACpE,QAAM,OAAO;AAAA,IACX,OAAO;AAAA,IACP,UAAU;AAAA,IACV,cAAa,aAAQ,WAAR,mBAAgB;AAAA,IAC7B,aAAY,aAAQ,WAAR,mBAAgB;AAAA,IAC5B,QAAO,aAAQ,WAAR,mBAAgB;AAAA,IACvB,OAAM,aAAQ,WAAR,mBAAgB;AAAA,IACtB,oBAAmB,aAAQ,WAAR,mBAAgB;AAAA,IACnC,aAAY,aAAQ,WAAR,mBAAgB;AAAA,IAC5B,WAAU,aAAQ,WAAR,mBAAgB;AAAA;AAAA,IAC1B,mBAAkB,aAAQ,WAAR,mBAAgB;AAAA,IAClC,OAAM,aAAQ,WAAR,mBAAgB;AAAA,IACtB,eAAc,aAAQ,WAAR,mBAAgB;AAAA;AAAA,IAC9B,OAAM,aAAQ,WAAR,mBAAgB;AAAA,IACtB,QAAO,aAAQ,UAAR,mBAAe,IAAI;AAAA,IAC1B,GAAG,QAAQ;AAAA,EACb;AAEA,QAAM,mBAAkB,aAAQ,WAAR,mBAAgB;AACxC,MACE,mBACA,yCAAyC,SAAS,eAAe,GACjE;AACA,QACE,oBAAoB,YACpB,iBAAM,KAAK,aAAX,mBAAqB,WAArB,mBAA6B,SAAS,UACtC;AACA,WAAK,kBAAkB;AAAA,QACrB,MAAM;AAAA,MACR;AAAA,IACF,WACE,oBAAoB,YACpB,iBAAM,KAAK,aAAX,mBAAqB,WAArB,mBAA6B,SAAS,UACtC;AACA,WAAK,kBAAkB;AAAA,QACrB,MAAM;AAAA,MACR;AAAA,IACF,OAAO;AACL,YAAM,IAAI;AAAA,QACR,GAAG,eAAe;AAAA,MACpB;AAAA,IACF;AAAA,EACF;AACA,aAAW,OAAO,MAAM;AACtB,QAAI,CAAC,KAAK,GAAG,KAAM,MAAM,QAAQ,KAAK,GAAG,CAAC,KAAK,CAAC,KAAK,GAAG,EAAE;AACxD,aAAO,KAAK,GAAG;AAAA,EACnB;AACA,SAAO;AACT;AAQO,SAAS,UAAU,MAAc,QAAgB;AACtD,SAAO,CACL,SACA,sBACkC;AAtftC;AAufI,QAAI;AACJ,UAAM,OAAO,oBAAoB,MAAM,OAAO;AAC9C,QAAI,mBAAmB;AACrB,YAAM,SAAS,OAAO,KAAK,KAAK,YAAY,OAAO,iCAC9C,OAD8C;AAAA,QAEjD,QAAQ;AAAA,MACV,EAAC;AACD;AAAA,mCAA0B,SAA1B,0EAAkC;AAAvB,gBAAM,QAAjB;AACE,sBAAM,YAAN,mBAAe,QAAQ,CAACA,WAAU;AAChC,kBAAM,IAAI,sBAAsBA,MAAK;AACrC,8BAAkB;AAAA,cAChB,OAAO,EAAE;AAAA,cACT,SAAS,EAAE,QAAQ;AAAA,YACrB,CAAC;AAAA,UACH;AAAA,QACF;AAAA,eARA,MA9fN;AA8fM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AASA,iBAAW,MAAM,OAAO,oBAAoB;AAAA,IAC9C,OAAO;AACL,iBAAW,MAAM,OAAO,KAAK,YAAY,OAAO,IAAI;AAAA,IACtD;AACA,WAAO;AAAA,MACL,YAAY,SAAS,QAAQ;AAAA,QAAI,CAAC,MAAG;AA5gB3C,cAAAC;AA6gBQ,kCAAiB,KAAGA,MAAA,QAAQ,WAAR,gBAAAA,IAAgB,YAAW,MAAM;AAAA;AAAA,MACvD;AAAA,MACA,OAAO;AAAA,QACL,cAAa,cAAS,UAAT,mBAAgB;AAAA,QAC7B,eAAc,cAAS,UAAT,mBAAgB;AAAA,QAC9B,cAAa,cAAS,UAAT,mBAAgB;AAAA,MAC/B;AAAA,MACA,QAAQ;AAAA,IACV;AAAA,EACF;AACF;AASO,SAAS,SACd,MACA,QACwC;AACxC,QAAM,UAAU,UAAU,IAAI;AAC9B,QAAM,QAAQ,qBAAqB,IAAI;AACvC,MAAI,CAAC;AAAO,UAAM,IAAI,MAAM,sBAAsB,IAAI,EAAE;AAExD,SAAO;AAAA,IACL;AAAA,MACE,MAAM;AAAA,OACH,MAAM,OAFX;AAAA,MAGE,cAAc,MAAM;AAAA,IACtB;AAAA,IACA,UAAU,MAAM,MAAM;AAAA,EACxB;AACF;","names":["chunk","_a"]}